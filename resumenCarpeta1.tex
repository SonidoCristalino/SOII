\documentclass[10pt, spanish]{article}

\usepackage{geometry} %Necesario para poder equiparar los márgenes
 \geometry{
    a4paper,
    total={170mm,257mm},
    left=20mm,
     top=20mm,
}
\usepackage[spanish]{babel}
\usepackage[latin1]{inputenc}

\usepackage{listings}
\usepackage{color}

\lstloadlanguages{C,C++,csh,Java}

\definecolor{red}{rgb}{0.6,0,0}
\definecolor{blue}{rgb}{0,0,0.6}
\definecolor{green}{rgb}{0,0.8,0}
\definecolor{cyan}{rgb}{0.0,0.6,0.6}
\definecolor{cloudwhite}{rgb}{0.9412, 0.9608, 0.8471}

\lstset{
    language=csh,
    basicstyle=\footnotesize\ttfamily,
    numbers=left,
    numberstyle=\tiny,
    numbersep=5pt,
    tabsize=2,
    extendedchars=true,
    breaklines=true,
    frame=b,
    stringstyle=\color{blue}\ttfamily,
    showspaces=false,
    showtabs=false,
    xleftmargin=17pt,
    framexleftmargin=17pt,
    framexrightmargin=5pt,
    framexbottommargin=4pt,
    commentstyle=\color{green},
    morecomment=[l]{//}, %use comment-line-style!
    morecomment=[s]{/*}{*/}, %for multiline comments
    showstringspaces=false,
    morekeywords={ abstract, event, new, struct,
    as, explicit, null, switch,
    base, extern, object, this,
    bool, false, operator, throw,
    break, finally, out, true,
    byte, fixed, override, try,
    case, float, params, typeof,
    catch, for, private, uint,
    char, foreach, protected, ulong,
    checked, goto, public, unchecked,
    class, if, readonly, unsafe,
    const, implicit, ref, ushort,
    continue, in, return, using,
    decimal, int, sbyte, virtual,
    default, interface, sealed, volatile,
    delegate, internal, short, void,
    do, is, sizeof, while,
    double, lock, stackalloc,
    else, long, static,
    enum, namespace, string},
    keywordstyle=\color{cyan},
    identifierstyle=\color{red},
    backgroundcolor=\color{cloudwhite},
}

\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{blue}{\parbox{\textwidth}{\hspace{15pt}#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white, singlelinecheck=false, margin=0pt, font={bf,footnotesize}}

\author{Emiliano Salvatori}
\title{Sistemas Operativos II\\
    \large Resumen Primera Parte}
\date{Agosto 2019}
\pagestyle{headings}

\begin{document}
\maketitle

\section{Clase nº 2}

\subsection{Concepto de Programa y sus Estados}

Un programa es una entidad pasiva, como el ejemplo en C escrito en clase. Solamente que es compilado y ejecutado. Esto
está estático en un disco, cuando se compila se convierte en una entidad activa, ya que se convierte en un proceso.

El concepto de proceso es mucho más que código compilado, tiene muchos más atributos que una simple ejecución de un
programa.

\textbf{Pregunta de examen}: realizar un grafo de los estados y explicarlos y tener en cuenta en poner los motivos de
las flechas.

\subsubsection{Estados}

Los tipos de Estados son los siguientes:
\begin{itemize}
    \item
        \textbf{Nuevo}: El proceso está siendo creado. Es cuando apenas se lanza un programa.  El equivalente sería a
        darle doble click a un lanzador en el Sistema Operativo o cuando se ejecuta por terminal: \emph{./ejecutable}.
        El proceso está siendo creado.
    \item
        \textbf{Preparado}: El proceso está a la espera de que le asignen tiempo para ejecutarse en el procesador. Lo
        que hace el SO es poner el programa en espera para los programas que están listos para correr en el procesador;
        se pueden visualizar por ejemplo cuando se corre \emph{htop} se listan estos estados de procesos. Que están esperando
        que el kernel le asigne tiempo para que se corra en el micro.
    \item
        \textbf{En ejecución}: Es cuando el SO le asigna tiempo dentro del procesador para poder ejecutar el código. El
        estado significa que se están ejecutando las instrucciones pertenecientes al proceso.
    \item
        \textbf{Espera}: Es un estado que se le asigna el SO cuando se produce por ejemplo un fallo de página.
        \footnote{Se denomina de esta forma a una excepción arrojada cuando un programa informático requiere una dirección que
        no se encuentra en la memoria principal actualmente. Recordar que los programas cargan en memoria de a pedazos,
        cuando no se encuentra ese pedazo en la siguiente instrucción a ejecutar, se produce el fallo de página}.

        O también se produce cuando realiza operaciones de E/S que tardan mucho tiempo en realizar la petición al
        hardware. Como esta petición tarda mucho tiempo, el SO pone al proceso en Espera y cuando le es devuelta la
        petición, lo vuelve a ejecutar. Según la filmina, el proceso está esperando a que se produzca un suceso.
    \item
        \textbf{Terminado}: Es el estado que el SO asigna a un proceso cuando terminó de ejecutar lo que debía de
        procesar.

\end{itemize}
\textbf{Significado de Interrupción}: El sistema operativo le otorga a cada proceso según un quantum un determinado
tiempo para ejecutarse dentro del procesador para luego quitarlo si es que no termina. Cuando se le acaba el tiempo para
correr, el proceso pasa nuevamente a \emph{preparado}. Importante: Las interrupciones se hacen por tiempo.

Los estados en los que pueda estar un proceso depeden también de lo que esté ejecutando el programa. Por ejemplo: Si se
pone un \emph{for} que hace muchas cuentas matemáticas, sólo estará en dos estados: Preparado y Ejecución porque la ALU por sí
sola puede realizar estas cuentas matemáticas, sin la necesidad de recurrir a ninguna otra petición externa.  En cambio
si en ese emph{for} se pone un imprimir por pantalla estará más tiempo en el estado de Espera.

\subsection{Bloque de control de procesos}

Se denomina Bloque de Control de Procesos al conjunto de atributos que tienen los procesos y que NO tiene un programa
compilado. Estas características no las poseen los programas estáticos.

\textbf{Pregunta de examen}: liste las caracteristicas del Bloque de Control de Procesos (PCB).

\begin{itemize}
    \item
        \textbf{Estado}: sería en qué lugar del grafo me encuentro. Qué estado le otorga el SO al proceso.
    \item
        \textbf{PID} : process ID es como el DNI del proceso.
    \item
        \textbf{Contador de programa}: puntero a la siguiente instrucción a ejecutar. Esto es indispensable porque el SO
        cada vez que quita un proceso del procesador porque se le acabó el tiempo de ejecución, requiere guardar las
        instrucciones en las que se quedó ejecutando, tiene que saber en qué parte de la ejecución quedó pendiente.
    \item
        \textbf{Registros del CPU}: Al igual que el punto anterior, también al quitar del procesador un proceso es
        necesario que se guarden las variables que estaba utilizando. Cuando el proceso se guarda porque se le acabó el
        quantum, debe tomar el registro de todas las variables que tiene el programa y guardarlas y saber en dónde
        terminó para que cuando se le vuelva a dar tiempo en el procesador saber desde dónde seguir.
    \item
        \textbf{Información de la planificación de la CPU}: Se tiene información acerca de la prioridad que el SO le da
        al proceso.
    \item
        \textbf{Información de gestión de memoria}: son los valores referidos a memoria utilizadad por el proceso, como
        ser: valor de registros básicos, tablas de paginación o segmentos, etc.
    \item
        \textbf{Información contable}: cuántos milisegundos corrió el proceso sobre el procesador, por ejemplo. Lleva la
        cuenta de cuánto tiempo estuvo corriendo el proceso.
    \item
        \textbf{Información de entrada salida}: qué dispositivo se está uttilizando, por ejemplo si hay un proceso que
        utiliza la impresora, el SO sabe que no puede asignar a otro proceso mientras el otro lo está utilizando.
\end{itemize}

\subsection{Concurrencia}
Dos procesos son concurrentes entre si, sólo si es que son independientes. Es decir, son independientes entre si cuando
no importa el orden en que se ejecute, el resultado es siempre el mismo. Por ejemplo: si hay un proceso que imprime "HOLA"
Otro proceso imprimie "PERRO" y se corren al mismo tiempo, son independientes porque no importa el orden el resultado
siempre es el mismo. El resultado de un proceso NO depende del resultado del otro.

Para que exista independencia en la ejecución de procesos, estos deben tener comunicación entre si. Por ejmplo cuando se
visita la página de Youtube y se reproduce un video. Un proceso está encargado de ir llenando el buffer del video
mientras que otro proceso está pendiente de si se aprieta play para poder comenzar a poner en secuencia las imágenes. El
primero de ellos siempre va adelante y siempre haciendo peticiones de E/S a la memoria asignada como buffer, manejándose
de forma independiente.

Para el usuario final, el resultado es el mismo, se ve el video. Pero los procesos que atienden estos servicios NO son
lo mismo, son varios procesos intercomunicados entre si brindando un mismo servicio. El programa en este caso es un
sistema concurrente.
\footnote{Dos o más procesos decimos que son concurrentes, paralelos, o que se ejecutan concurrentemente, cuando son procesados
almismo tiempo, es decir, que para ejecutar uno de ellos, no hace falta que se haya ejecutado otro.}

Las cuestiones a tener en cuenta a la hora de diseñar procesos concurrentes:

\begin{itemize}
    \item
        Comunicación entre procesos.
    \item
        Compartición y competencia por los recursos.
    \item
        Sincronización de la ejecución de varios procesos.
    \item
        Asignación del tiempo del procesador a los procesos.
\end{itemize}


\subsection{Paralelismo}
Capacidad de ejecutar procesos de manera paralela. Está asociado al hardware. La única manera de ejecutar dos procesos A
y B a la vez, es que lo permita el hardware. Se tiene cuando hay mas de un cause por los que se puede ejecutar un
proceso, y esto lo dispone el hardware.
Antes tenían procesadores con un solo cause, se corría un solo proceso dentro de un solo procesador. En los 80 se
inventaron varios causes y al día de hoy los causes se duplicaron.

Recordar que \textbf{Paralelismo NO implica concurrencia}. Si se tiene paralelismo (con hardware adecuado) se va a
necesitar la capacidad de correr procesos concurrentes. \textbf{Pero para que haya Concurrencia es necesario que haya
Paralelismo}

\subsection{Gestión de procesos}

\textbf{Multiprogramación}: tener un solo cause y dividir en tajadas de tiempo varios programas y tener la sensación de
que sucede todo a la vez.
Se denomina multiprogramación a una técnica por la que dos o más procesos pueden alojarse en la memoria principal y ser
ejecutados concurrentemente por el procesador o CPU.

Hay que tener en cuenta que los procesos van intercambiandose entre si un tiempo el proceso P1, otro tiemp el P2 y puede
haber un P3 que lo utilice otro tiempo. Lo que NO puede pasar es que se superpongan los Procesos.

\textbf{Multiprocesamiento}: es tener varios causes. Se tiene varios procesadores para varios procesos.
Multiprocesamiento o multiproceso es el uso de dos o más procesadores (CPU) en una computadora para la ejecución de uno
o varios procesos (programas corriendo). Si se tiene multiprocesador se puede tener por ejemplo a P1 y P2 corriendo en
simultaneo (dependiendo de cuántos cause tenga el procesador).

\textbf{Procesamiento distribuido}: Consiste en la gestión de varios procesos, ejecutándose en sistemas de computadoras
múltiples y distribuidos. Es la idea de cluster.

La computación distribuida o informática en malla (grid) es un modelo para resolver problemas de computación masiva
utilizando un gran número de ordenadores organizados en clústeres incrustados en una infraestructura de
telecomunicaciones distribuida.

\subsection{Función Fork}
La función fork(), se utiliza para crear un nuevo proceso duplicando el proceso de llamada actual, siendo el proceso
recién creado conocido como \textbf{proceso hijo} y el proceso de llamada actual conocido como \textbf{proceso padre}.
Entonces podemos decir que fork () se usa para crear un proceso secundario al proceso de llamada.

Con esta instrucción, el cause de ejecución no es de arriba hacia abajo como en un programa simple realizado en C, sino
que se tiene un cause distinto, bifurcado. Se puede correr de forma concurrente. Se tene dos procesos simultaneamente
por ejemplo:

%codigo del ejemplo5.c

Como se puede ver \emph{fork()} lo que hace es crear un proceso nuevo, es decir un proceso hijo pero dentro de la
ejecución del proceso padre. Lo que hace el SO cuando encuentra esta instrucción es duplicar el espacio de memoria del
padre, compartiendo todas las variables.  Copia toda la memoria estática al proceso hijo.

Se debe recordar que Minix tiene una tabla de procesos que sólo puede albergar 100 procesos (de 0 a 99). Si se llena esa
tabla, el fork() da error, simbolizando su valor de retorno con un -1. Solo puede crear 99 procesos nada más. El fork()
da -1 y sale con error y este error lo toma el SO en el cause del proceso que lo invocó.

Con el fork no se puede saber cuándo un proceso se ejecuta primero. Por lo que se puede utilizar la función \emph{sleep()} en
el del hijo. Para dormir al hijo y que ejecute el hijo y no el padre.

\textbf{Pregunta de examen}: ¿existe otro estado que no sea el de \emph{terminado}? Este estado posible se denomina
\emph{Estado Zombie}, que es cuando el hijo no tiene nada que ejecutar y está esperando que el padre muera o al revés.
En sistemas operativos Unix, un proceso zombi o "defunct" (difunto) es un proceso que ha completado su ejecución pero
aún tiene una entrada en la tabla de procesos, permitiendo al proceso que lo ha creado (padre) leer el estado de su
salida.  Metafóricamente, el proceso hijo ha muerto pero su "alma" aún no ha sido recogida.

\textbf{Preguna de examen}: Escriba un código en C donde un proceso A cree un proceso hijo B. Esto sería similar a poner
el \emph{ejemplo5.c} citado anteriormente.

Se debe tener en cuenta que el PID puede tener 3 valores:
\begin{itemize}
    \item
        Un número mayor que cero.
    \item
        Un número igual a cero. Puede ser cero por ejemplo para el PID del hijo de un proceso padre
    \item
        Un número igual a -1.
\end{itemize}

\subsection{Hilos y procesos multihilo}
Proceso padre tiene un espacio de memoria asociado y luego tiene un código.  En el espacio tiene la pila, los datos, el
contador de programa. Y tiene un solo cause. Cuando se hace invoca a la función fork(), se crea un hijo idéntico, lo que
cambia solo es el PID. Por lo que es costoso en tiempo y en recurso invocar un fork().

Un proceso de Unix es cualquier programa en ejecución y es totalmente independiente de otros procesos. El comando de
Unix \emph{ps} nos lista los procesos en ejecución en nuestra máquina. Un proceso tiene su propia zona de memoria y se ejecuta
"simultáneamente" a otros procesos

La idea de hilo es agarrar el procso y utilizar el mismo tamaño de memoria de un solo proceso pero hacer correr varias
hebras. Esto tiene muchos más beneficios que desdoblar un proceso en dos, ya que los hilos comparten espacio de memoria.
Los hilos ya de por sí comparten espacio de salida. Cada hebra corre por distintos causes, si una se bloquea el proceso
sigue consumiendo tiempo en el procesador ejecutando otros hilos y no saca el proceso de su ejecución como SI sucedería
con un proceso hijo y padre.

Dentro de un proceso puede haber varios hilos de ejecución (varios threads). Eso quiere decir que un proceso podría
estar haciendo varias cosas ''a la vez''. Los hilos dentro de un proceso comparten todos la misma memoria. Eso quiere
decir que si un hilo toca una variable, todos los demás hilos del mismo proceso verán el nuevo valor de la variable.
Esto hace imprescindible el uso de semáforos o mutex (EXclusión MUTua, que en inglés es al revés, funciones
\emph{pthread\_mutex}) para evitar que dos threads accedan a la vez a la misma estructura de datos. También hace que si un
hilo "se equivoca" y corrompe una zona de memoria, todos los demás hilos del mismo proceso vean la memoria corrompida.
Un fallo en un hilo puede hacer fallar a todos los demás hilos del mismo proceso.

\textbf{Conclusión:} Un proceso es, por tanto, más costoso de lanzar, ya que se necesita crear una copia de toda la
memoria de nuestro programa. Los hilos son más ligeros.

Ventajas de la programación multihilo:

\begin{itemize}
    \item
        \textbf{Capacidad de respuesta}: permite que un programa continúe ejecutándose incluso aunque parte de él esté
        bloqueado.
    \item
        \textbf{Compartición de recursos}: por omisión, las hebras comparten la memoria y los recursos del proceso al
        que pertenecen.
    \item
        \textbf{Economía}: asignar memoria y recursos para crear procesos es costosa, es más económico realizar cambios
        de contexto entre hebras.
    \item
        \textbf{Multiprocesador}: se pueden ejecutar en paralelo en diferentes procesadores (un proceso monohebra solo
        se puede ejecutar en un sólo microprocesador).
\end{itemize}


\subsection{Instancias de Kernel}
\textbf{Modelo Muchos a Uno}: Otra forma es que muchas hebras llaman a una sola instanacia de kernel. Es un costoso cuando hay muchas
hebras. Es eficiente pero el proceso completo se bloquea si una hebra realiza una llamada bloqueante al sistema.

\textbf{Modelo Uno a uno}: Asigna cada hebra de usuario a una de Kernel. Todo el tiempo se hacen solicitudes al kernel
(como por ejemplo imprimir en pantalla). Cuano se tienen hebras se pueden una instancia de kernel que le responda a cada
hebra. Cada hebra hace una solicitud a una instanaica del kernel. Esto se denomina Uno a Uno: un hilo solicita una
instancia de Kernel. Este modelo proporciona mayor concurrencia que el anterior, se permiten herbas bloqueantes mientras
se ejecutan otras. El incovenviente de ello es que crear una hebra de usuario requiere crear su correspondiente hebra de
kernel por lo que repercute en el rendiemiento

\textbf{Modelo muchos a muchos}: La solución que se da es un híbrido entre ambas: muchos hilos solicitan al kernel una
instancia en particular y el kernel evalúa cuándo crear una instancia para cada hebra.
Multiplexa muchas hebras de usuario sobre un número menor o igual de hebras de Kernel. Se pueden crear tantas hebras de
usuario como sea necesario y las correspondientes hebras del Kernel pueden ejecutarse en paralelo en un multiprocesador.
Cuando una hebra realiza una llamada bloqueante, el kernel planifica otra hebra.

\subsection{Hilos en modo Usuario}
Los hilos en modo usuario tienen determinadas ventajas:

\begin{itemize}
    \item
        El núcleo no sabe que existen.
    \item
        Tabla de subprocesos probada para cambios de contexto.
    \item
        Cambio de contexto mucho mas rápido entre hilos (no se pasa al kernel).
    \item
        Cada proceso puede tener su algoritmo de planificación.
\end{itemize}

Inconvenientes:
\begin{itemize}
    \item
        Llamadas bloqueantes al sistema.
    \item
        Fallos de página.
    \item
        Tienen que ceder la CPU entre ellos: conmutación en el mismo proceso.
    \item
        Precisamente queremos hilos en procesos con muchas E/S para obtener paralelismo, es decir que se están
        bloqueando muy frecuentemente.
\end{itemize}

\subsection{Hilos en Modo Kernel}
Ventajas:
\begin{itemize}
    \item
        El núcleo mantiene la tabla de hilos, que es un subconjunto de la de procesos.
    \item
        Las llamadas bloqueantes no necesitan funciones especiales.
    \item
        Los fallos de página no suponen un problema.
    \item
        Al bloquearse un hilo, el núcleo puede conmutar a otro hilo de otro proceso.
\end{itemize}

Inconvenientes
\begin{itemize}
    \item
        Las llamadas bloqueantes son llamadas al sistema.
    \item
        La creación y destrucción de procesos es mas costoso, por lo que se trata de reutilizar hilos.
\end{itemize}

\subsection{Diferencia entre procesos e hilos}

Creación:
\begin{itemize}
    \item
        \textbf{Procesos}: son costosos para crear
    \item
        \textbf{Hilos}: son bastante ligeros
\end{itemize}

Recursos(memoria):
\begin{itemize}
    \item
        \textbf{Procesos}: Independientes
    \item
        \textbf{Hilos}: Compartidos
\end{itemize}

Comunicación:
\begin{itemize}
    \item
        \textbf{Procesos}: compleja
    \item
        \textbf{Hilos}: Sencilla
\end{itemize}

Cambio por Sistema operativo:
\begin{itemize}
    \item
        \textbf{Procesos}: Muy lento
    \item
        \textbf{Hilos}: Rápido
\end{itemize}

Proramación:
\begin{itemize}
    \item
        \textbf{Procesos}: Reducida
    \item
        \textbf{Hilos}: Alta
\end{itemize}

\section{Clase nº 3}

\subsection{Recursos}


En SO se puede determinar que los Recursos:
\begin{itemize}
    \item
        \textbf{Apropiativos}: Un recurso apropiativo es uno que se puede quitar al proceso que lo posee sin efectos
        dañinos. La memoria es un ejemplo de un recurso apropiativo. Por ejemplo, un recurso de este tipo es el
        microprocesador, el cual se cede por determinado tiempo a cada recurso y luego se lo expropia.
    \item
        \textbf{No apropiativos}: Un recurso no apropiativo es uno que no se puede quitar a su propietario actual sin
        hacer que el cómputo falle. Si un proceso ha empezado a quemar un CD-ROM y tratamos de quitarle de manera
        repentina el grabador de CD y otorgarlo a otro proceso, se obtendrá un CD con basura.
\end{itemize}

Para las gráficas, los Recursos se dibujan como cajas y los procesos como círculos o burbujas.
Hay recursos que tienen dos puntos que significa que el recurso tiene dos instancias, es un mismo recurso como
subdividdo; cuando se toma el puntito en el diagrama, se debe especificar qué tipo de sub-recurso está tomando de ese
recurso (de la caja general).

\subsection{Deadlock/Interbloqueo/Abrazo Mortal}

Para que exista un Deadlock deben darse 4 condiciones:

\begin{itemize}
    \item
        \textbf{Exclusión Mutua}: debe haber recursos no compartidos de uso exclusivo, es decir, cada recurso se asinga
        a un solo proceso en un momento dado. Recursos no compartidos de uso esclusivo, es cuando ese recurso se lo
        hace un proceso, ese recurso queda bloqueado para ese proceso.
        Cada recurso se asigna en un momento dado a sólo un proceso, o está disponible.
    \item
        \textbf{Hold and Wait (contención y espera)}: se toma un recurso y se espera por otro. (Flecha que entra hacia el
        proceso, quiere decir que ese recurso esta reternido por el proceso, cuando la flecha está desde el proceso al
        recurso, el proceso está pidiendo ese recurso).
        Los procesos que actualmente contienen recursos que se les otorgaron antes pueden solicitar nuevos recursos.
    \item
        \textbf{Condicion no apropiativa}: significa que una vz que se le dio un recurso a un proceso, no se lo puede
        expropiar. El micro NO estaría en esta condición ya que se cede a un proceso y luego se lo saca todo el tiempo.
        Los recursos otorgados previamente no se pueden quitar a un proceso por la fuerza. Deben ser liberados de
        manera explícita por el proceso que los contiene.
    \item
        \textbf{Espera circular}: es una cadena circular donde cada proceso está esperando un recurso que está siendo
        tomado/utilizado por otro.
        Debe haber una cadena circular de dos o más procesos, cada uno de los cuales espera un recurso contenido por el
        siguiente miembro de la cadena.

\end{itemize}

\subsubsection{Algoritmo de la avestruz}

El algoritmo del avestruz es un concepto informático para denominar el procedimiento de algunos sistemas operativos.
Esta teoría, acuñada por Andrew S. Tanenbaum, señala que dichos sistemas, en lugar de enfrentar el problema de los
bloqueos mutuos (deadlock en inglés), asumen que estos nunca ocurrirán.
Ingenieros vs Matemáticos: los últimos quieren darle solución y los ingenieros decían que no hacía falta porque la
probablilidad de que suceda un interbloqueo era baja, por lo tanto no hay que hacer nada.

\textbf{¿Cómo se da cuenta de un deadlock?}
Hay una solución que se puede realizar realizando Grafos [ver carpeta]. Se comienza siempre por algún proceso externo
(en el caso es B) y se siguen las flechas.

\subsubsection{Detección y Recuperación}

Lo que se hace es tomar el primer elemento del arreglo y se compara contra todos los elementos restantes. Si no existe
repetido entonces se pasa al siguiente elemento y así con todos. La relación es todos contra todos.

Hay momentos en donde se pueden generar más sub-listas porque pueden haber otros caminos (recursos y procesos posibles)
lo que genera un grafos más grande, haciendo que el algoritmo se vuelva muy costoso.

La ventaja de éste algoritmo de Detección y Recuperación es que \emph{es simple} de implementar. Pero la desventaja como
se nombró anteriormente, es que \emph{es costoso} en lo que respecta a la capacidad de cómputo.

    \[Lista = [B]\]
    \[Lista = [B, T]\]
    \[Lista = [B, T, E]\]
    \[Lista = [B, T, E, V]\]
    \[Lista = [B, T, E, V, G, U]\]
    \[Lista = [B, T, E, V, G, U, D]\]
    \[Lista = [B, T, E, V, G, U, D, T]\]

Se puede ver que en la última iteración vuelve a a parecer el recurso T, por lo que existe una espera circular.
Se puede observar que además este tipo de algoritmo debe ser recursivo por lo que se tiene una complejidad mucho mayor
en consumo de recursos de memoria.

\subsubsection{Algoritmo del Banquero}

El algoritmo mantiene al sistema en un \emph{estado seguro}. Un sistema se encuentra en un estado seguro si existe un orden en
que pueden concederse las peticiones de recursos a todos los procesos, previniendo el interbloqueo. El algoritmo del
banquero funciona encontrando estados de este tipo.

Los procesos piden recursos, y son complacidos siempre y cuando el sistema se mantenga en un estado seguro después de la
concesión. De lo contrario, el proceso es suspendido hasta que otro proceso libere recursos suficientes.

%Debería ir un gráfico acá de las iteraciones

\textbf{Nota}: Si hubiera un deadlock se harán varias iteraciones y la cantidad de disponibles no podrá satisfacer ls
procesos. En este algoritmo no importa el orden de los procesos, se irán terminando sin orden, sino que depende de los recursos
que vaya slicitando para temrinar.  En los examenes si llega el caso de producirse un Deadlok, terminaría el ejercicio
señalandose que se llegó a un deadlock.

\subsubsection{Inanición}
En informática, inanición (starvation en inglés) es un problema relacionado con los sistemas multitarea, donde a un
proceso o un hilo de ejecución se le deniega siempre el acceso a un recurso compartido. Sin este recurso, la tarea a
ejecutar no puede ser nunca finalizada.

La inanición NO es sinónimo de interbloqueo, aunque el interbloqueo produce la inanición de los procesos
involucrados. La inanición puede (aunque no tiene porqué) acabar, mientras que un interbloqueo no puede finalizar sin
una acción del exterior.


\subsection{Comunicación entre procesos (IPC)}

Hay que tener en cuenta que la función \emph{fork()} tiene el siguiente funcionamiento: cuando se ejecuta un código
cuyo flujo es de arriba hacia abajo y se encuentra con la función fork(), lo que sucede es que a partir de ese momento
el programa se \textbf{duplica}, es decir que el SO coloca en el espacio de memoria dos imagenes totalmente iguales del
mismo código. Es por ello que luego de la llamada a fork() es necesario escribir el código del proceso hijo y luego el
código del proceso padre mediante el condicional sobre el número del PID. Cuando el programa copia A ejecuta el mismo
código que su hijo B, encuentra el condicional y entra al código escrito para su PID. Cuando el otro proceso B con el
mismo código que A encuentra el código con el IF haciendo mención a su PID, entra a ejecutar ese código.

También sucede que PID dentro de la memoria del proceso, será 0 y para el padre será mayor que 0.

\lstinputlisting[language={C}]{clase3/ejemplo1.c}

Se utiliza la función \emph{getppid()} (get process PID) que se encuentra en la librería \emph{unistd.h} para que cada
uno de los procesos devuelva el PID de su proceso padre. Tener en cuenta que si esta función es invocada desde el
proceso padre (en nuestro caso el A), devolverá el PID del proceso que está corriendo la consola.

Es posible que dos procesos generados a partir de fork() se comuniquen entre si, y es utilizando tuberías o
\emph{pipelines}.

Las funciones \emph{sleep()} se utilizan para poder detener la ejecución del padre durante los segundos que se le
indiquen como parámetro y poder visualizar su aparición en la tabla de proceso mediante el comando \emph{top} de la
siguiente forma: \[\$ \emph{top -U usuario} \]


Existen dos formas para comunicar procesos:

\begin{enumerate}
    \item
        \textbf{Por Memoria compartida}: Se utiliza Un espacio de memoria común entre procesos donde un proceso  escribe
        y el otro lee. La ventaja de ello es que al utilizar memoria es más rápida en lo que respecta a escribir y leer.
        Lo complejo de este método es que para que ambos procesos compartan una parte de memoria en común, se requiere
        que exista sincronía entre ellos, de forma contraria se podrían producir colapsos.
        En sistemas multiusuarios como los que existían antaño, es imposible implementarlo, como tampoco en sistemas
        distribuidos. Tampoco se puede implementar en algunos microprocesadores de IBM los cuales al tener la
        característica de tener varios procesadores juntos conectados en forma de anillo, y donde cada procesador tiene
        una memoria caché exclusiva, se hace imposible que esa memoria dedicada a un procesador la comparta con otro
        procesador.
    \item
        \textbf{Por pasaje de mensaje}: La característica que tiene es que es menos rápida ya que no comparte un espacio
        de memoria como en el anterior, pero al no verse obligado a implementar un sistema de sincronización, es mucho
        más fácil de implementar. Ejemplo de estos pasajes son: sockets, pipes, mensajes, buzones.
        Se suele utilizar esto por ser más simple.
\end{enumerate}

\subsubsection{Características de las comunicaciones entre procesos}

\begin{itemize}
    \item
        \textbf{Comunicación Directa/indirecta (en el SO)}: Cuando es directa cada proceso debe nombrar explicitamente
        al otro proceso con el que se quiere comunicar.
    \item
        \textbf{Comunicación indirecta}: asociado con lo que tiene que ver con buzones, NO se utiliza el PID del
        proceso con el que se comunica
    \item
        \textbf{Sincronica}: suelen ser bloqueantes porque es como hablar con el teléfono, el
        proceso no puede seguir haciendo otra cosa que no sea comunicarse y reservarse
        para eso.
    \item
        \textbf{Asincronica}: es que puede enviar el mensaje y luego pasar a hacer otra cosa.
        Correo postal o mensaje de whatsapp.
    \item
        \textbf{Envío y recepción Bloqueante}:

        El emisor espera hasta que el mensaje ha sido entregado

        El receptor espera hasta que le llegue el primer mensaje
    \item
        \textbf{Envío y recepción No Bloqueante}:

        El emisor no resulta bloqueado en ningún caso

        El receptor tampoco

        La función recibir devuelve error si no hay mensajes disponibles
    \item
        \textbf{Simetrica}: los dos procesos tienen que tener los PID para comunicarse. Nombra a
        quien escribe y el otro nombra de quien recibe. Se basa en saber si cada uno
        tiene el PID del otro.
    \item
        \textbf{Asimetrica}: solo un proceso que tiene que tner el PID de uno para escribirle, el
        otro no lo tiene. Uno lo sabe y el otro no.
\end{itemize}

\subsubsection{Buzones}


Los Buzones son una herramienta que provee el So para poder comunicarse entre procesos. Existen tres formas de
realizarlos:
\begin{itemize}
    \item
        \textbf{Uno a uno}: un proceso manda a un buzón y el otro lee
    \item
        \textbf{Muchos a uno}: más de un proceso que escriba y que uno solo lea desde el buzón.
    \item
        \textbf{Uno a muchos}: comunicación de broadcasting, como la antena de la radio emitiendo para todos.
\end{itemize}

¿De qué depende qué buzon implementar? Depende de la velocidad de los procesos a la hora de emitir los mensajes y cuánto
tarden en recepcionarlo y leerlos, por eso es que algunas veces es necesario poner muchos emisores porque el receptor es
lento o varios receptores porque los procesos son lentos al leer los mensajes enviados.

\subsubsection{Características del canal}

Según su Capacidad:
\begin{itemize}
    \item
        \textbf{infinita}:, ninguno tiene infinito, toda comunicación tiene un máximo
    \item
        \textbf{cero}: que está cortada la comunicación. Que no existe un canal.
    \item
        \textbf{Limitada}: todas las comunicacionee son limintadas.
\end{itemize}

Según el Tipos de mensaje:
\begin{itemize}
    \item
        \textbf{Largo fijo}:
    \item
        \textbf{Largo variable}: TCP, el que se usa en internet.
\end{itemize}

\subsubsection{Tuberias o Pipelines}

Para que dos procesos se comuniquen entre sí es necesario que lo hagan mediante lo que se denomina \emph{tuberías o
pipelines}. La comunicación por medio de tuberías se basa en la interacción productor/consumidor, los procesos
productores (aquellos que envían datos) se comunican con los procesos consumidores (que reciben datos) siguiendo un
orden FIFO. Una vez que el proceso consumidor recibe un dato, éste se elimina de la tubería.

El siguiente es un ejemplo de cómo proceder en lenguaje C para poder establecer una tubería:

\lstinputlisting[language={C}]{clase3/ejemplo3.c}

Se deben aclarar los siguientes puntos:

\begin{itemize}
    \item
        \textbf{string.h}: se incluye la librería para el tratamiento de cadenas.
    \item
        \textbf{stdlib.h}: se incluye la librería para la función \emph{exit} en caso de que haya algún error creando el
        proceso hijo.
    \item
        \textbf{fd[2]}: es un vector de dos elementos que sirve como file descriptor para la comunicación de procesos.
        Sería la tubería respectivamente.
    \item
        \textbf{buffer[80]}: es la variable que alojará lo recibido por el proceso A. Dentro de \emph{buffer} se
        guardará lo que el proceso padre recibe, que en este caso es una cadena que dice ''hola mundo''.
    \item
        \textbf{pipe()}: es la función encargada de tomar el vector de enteros denominado \emph{fd} y convertirlos en
        file descriptos para que se comuniquen los procesos. Según la página de manual de \emph{pipe()} dice lo
        siguiente:
        \emph{The pipe() function shall create a pipe and place two file descriptors, one each into the arguments fildes[0]
        and fildes[1], that refer to the open  fileescriptions  for  the  read and write ends of the pipe.
        Data  can  be  written  to the file descriptor fildes[1] and read from the file descriptor fildes[0].  A read on
        the file descriptor fildes[0] shall access data written to the file descriptor fildes[1] on a first-in-first-out
        basis}.
    \item
        \textbf{close()}: Siempre se debe invocar esta función tanto sea en el padre como en el hijo antes de utilizar
        cada \emph{fd[]}. Se debe cerrar el \emph{fd} que no se utilizará y utilizar el otro para la comunicación.
    \item
        \textbf{write()}: \[ssize\_t write(int fildes, const void *buf, size\_t nbyte);\]
        Según el manual, la función \emph{write()} permite escribir \emph{nbytes} de tamaño desde el buffer apuntado
        como \emph{buf} al archivo asociado con el file descriptor abierto \emph{fields}. La función devuelve un tamaño
        de bytes escritos.
    \item
        \textbf{read()}: \[ssize_t read(int fildes, void *buf, size_t nbyte);\]
        Según el manual: la función \emph{write()} intentará leer \emph{nbytes} desde el archivo apuntado por el file
        descriptor abierto \emph{fildes}, al buffer apuntado como \emph{buf}. La función devuelve un tamaño de bytes
        leídos.
    \item
        \textbf{sizeof()}: Permite saber el tamaño en bytes de su argumento, sin importar que sea un dato primitivo o un
        dato creado por el usuario, como ser un struct.
\end{itemize}

Hay otras formas de hacer una tubería mediante consolas:

En la primer consola colocar:
\begin{enumerate}
    \item
        \emph{mknod tubo p}
    \item
        \emph{ls -l}
    \item
        \emph{cat $<$ tubo}
\end{enumerate}

En la segunda consola colocar:
\begin{enumerate}
    \item
        \emph{cat $>$ tubo}
\end{enumerate}

\section{Clase nº 3 - Sincronización}

\subsection{Procesos Cooperativos}

\textbf{Definición}: Son aquellos que puede afectar o verse afectado por otros procesos que estén ejecutándose en el
sistema. Estos pueden compartir espacio de direcciones y comparten datos a través de mensajes.

Las razones por las que se implementan estos procesos
\begin{itemize}
    \item
        \textbf{Compartir información}: varios usuarios pueden estar interesados en compartir información.
    \item
        \textbf{Acelerar cálculos}: atomizar tareas y ejecución en paralelo.
    \item
        \textbf{Modularidad}: Construcción del sistema en forma modular
    \item
        \textbf{Convivencia}: múltiples tareas o procesos ejecutándose al mismo tiempo.
\end{itemize}

\subsection{Memoria Compartida}

Los procesos intercambian información leyendo y escribiendo en lo que se denomina \emph{zonas compartidas}. Estas zonas
son más rápidas para el transpaso de mensajes ya que como se dijo en la clase anterior, al utilizar memoria, es mucho
más rápido el acceso a esta, que otros medios.

La memoria compartida es aquel tipo de memoria que puede ser accedida por múltiples programas, ya sea para comunicarse
entre ellos o para evitar copias redundantes. La memoria compartida es un modo eficaz de pasar datos entre aplicaciones.
Dependiendo del contexto, los programas pueden ejecutarse en un mismo procesador o en procesadores separados. La memoria
usada entre dos hilos de ejecución dentro de un mismo programa se conoce también como memoria compartida

\subsection{Productor/Consumidor}

El problema Productor/Consumidor consiste en el acceso concurrente por parte de procesos productores y procesos
consumidores sobre un recurso común que resulta ser un buffer de elementos. Los productores tratan de introducir
elementos en el buffer de uno en uno, y los consumidores tratan de extraer elementos de uno en uno.

Para asegurar la consistencia de la información almacenada en el buffer, el acceso de los productores y consumidores
debe hacerse en exclusión mutua. Adicionalmente, el buffer es de capacidad limitada, de modo que el acceso por parte de
un productor para introducir un elemento en el buffer lleno debe provocar la detención del proceso productor. Lo mismo
sucede para un consumidor que intente extraer un elemento del buffer vacío.

Cuando se utiliza memoria compartida los procesos que utilicen la memoria compartida o también denominado \emph{Zona
Crítica o Sección Crítica} deben estar \textbf{sincronizados} para que el consumidor no intente consumir cuando el
productor no escribió aún.

\textbf{Buffer}: Buffer es un vector de memoria que se organiza de forma consecutiva. Es por ello que se plantea el
problema de ¿Qué sucede si se sigue produciendo datos cuando termina el vector? Los programas deben tener en cuenta esto
por lo que se deben programar de manera circular para que apunte a la primera posición una vez que el buffer se
encuentra desbordaro. Hay que tener en cuenta que cuando los dos punteros tanto del productor como del consumidor,
apuntan a la misma dirección de memoria dentro del buffer, significa que está vacio.


Todos los problemas de consumidor/producor tiene una variable entera que se denomina \emph{counter} que es la encargada
de llevar el conteo de los elementos encerrados dentro del buffer. Por lo tanto:
\begin{itemize}
    \item
        El proceso Productor lo que hace es counter++, es decir, aumentar en una unidad la variable contador.
    \item
        El proceso Consumidor lo que hace es counter--, es decir, disminuir en uno la variable contador.
\end{itemize}

Hay que tener en cuenta que tanto la variable que se utiliza de contador,  como el buffer se encuentra en la Sección
critica y tanto el proceso Productor como el Consumidor utilizarán ambas cosas.
Es por ello que se debe asegurar que sólo uno de ellos pueda entrar por vez a la Sección Crítica. Esto se denomina
\emph{exclusión mutua}.

Un ejemplo de cómo proceden los procesos que hacen de Productor y Consumidor:
\begin{itemize}
    \item
        \textbf{Productor}: El productor se le da la posibilida para poder utilizar la \emph{Sección Crítica} por lo que
        accede al buffer y produce un dato. Acto seguido le suma a la variable contador 1 unidad y el proceso finaliza
        dejando libre la Sección Critica.
    \item
        \textbf{Consumidor}: El proceso que auspicia de Consumidor, al tener libre el acceso a la memoria, incresa y
        consume un dato del buffer y le resta a la varible contador una unidad. El proceso al finalizar esto, deja libre
        la Sección Crítica.
\end{itemize}

El código en Assembler sería algo así:

        counter++
        reg1 = counter
        reg1 = reg1 + 1
        counter = reg1

\textbf{Secuencia}: En la primera línea lo que sucede es que se adelanta en una posición el puntero del contador. Cuando
la variable \emph{reg1} carga la variable counter se guarda en el registro de la memoria, luego se le suma el literal y
se vuelve a guardar en el registro de memoria, con el nuevo valor \emph{counter + 1}.

Esto lo realiza el primer proceso denominado Productor (ya que produce un dato). Como son dos procesos los involucrados
en la Sección Crítica, entonces puede suceder que el Schedule no le asigne más tiempo en el procesador al proceso del
Productor, pasándolo a un estado \emph{En Espera} en el medio de la creación del dato y la actualización de las
variables \emph{counter} y \emph{reg1}, y acto seguido le asigne el microprocesador al proceso del Consumidor.

El ejemplo de la ejecución sería el siguiente:
        reg1 = counter  == reg1 = 3
        reg1 = reg1 + 1 == reg1 = 4
        reg2 = counter
        reg2 = reg2 - 1 == reg2 = 3
        counter = reg2  == reg2 = 2
                        counter = 4
        counter = reg1 == counter = 4

La posible solución a esto es que cuando el proceso Productor se ejecute, se haga para sí de la memoria compartida,
produzca el dato, adelantar el puntero a la siguietne espacio de memoria. Todo ello lo debe hacer SIN que el proceso de
consumidor se meta antes de que termine.

En la filmina se trata de ejemplificar esto con la idea de una autopista que cuenta la cantidad de coches que pasan por
un peaje. ¿Qué sucede si pasan dos coches a la misma vez? El contador entraría en problemas ya que no podría divisar
esto como dos autos.

\subsection{Posibles Soluciones}

La solución filosófica al problema del Productor/Consumidor la esgrimió Decker, pero fue Peterson quien volcó al código
e implementó las ideas del primero.

\subsubsection{Solución nº 1}

La aproximación que plante Deker se explica mediante un iglú que funcionaría como una variable, y dos esquimales, que
vendrían a ser dos procesos.

Sólo un proceso entra por la puerta del iglu, dentro ve en una pizarra, escrito el nº 1, sale del iglú, toma la lanza
(es el recurso compartido), y va a cazar, vuelve y escribe el nº 2.
El proceso nº 2 entra al iglu, ve el número 2 escrito en la pizarra, toma la lanza y sale a cazar, cuando vuelve pone el
1 y el proceso se repite una y otra vez.
\begin{itemize}
    \item
        \textbf{Ventajas}: Se asegura la exclusión mutua, no hay ninguna manera de que los dos estén dentro en un mismo momennto.
    \item
        \textbf{Desventajas}: si el proceso nº 1 muere cazando un oso por ejemplo, no vuelve nunca, por lo que el otro
        no entra a la sección crítica nunca más.
        Los procesos están acompasados, lo que significa que si existe un proceso que utiliza mucho la sección crítica, y
        el otro poco tiempo, el problema es que al estar acompasados, el proceso que marcará el paso es el que lo
        utiliza menos tiempo, por lo que volverá la performance lenta.
\end{itemize}

\subsubsection{Solución nº 2}

Se plantea el mismo problema que el nº 1, donde existe otro iglu (una segunda variable variable) por lo que serían dos
iglu. Los dos procesos entrarían en distintos inglus. Las pizarras se encuentran por defecto en \emph{falso} (libres)
¿Cómo hacen los esquimales para entrar en la Sección Crítica?

El procedimiento es el siguiente: El proceso nº 1 entra al iglu nº 2 y ve falso, vuelve al suyo y pone verdadero, por lo
que da a entender que se encuentra en la Sección Crítica.
El proceso nº 2 va al iglu nº 1 y ve \emph{verdadero} entonces lo que hace es esperar. El proceso nº 1 cuando termina
pone falso y se repite esto para ambos procesos cuando quieran acceder a la Sección Crítica.

La problemática que conlleva esta solución:
\begin{itemize}
    \item
        Si dos esquimales se cruzan y ponen verdadero las dos pizarras. Se complejiza el problema debido a que en este
        planteo existen dos iglu, a diferencia del anterior que existía sólo uno, al haber uno se asegura la exlusión mutua.
    \item
        El problema del planteo nº 1 es el tiempo que lleva cada proceso dentro de la Exclusión Mutua.
\end{itemize}

\subsubsection{Solución nº 3}

La tercer solución que se plantea también existen dos iglues como en la solución anterior.
El Proceso nº 1 entra a su iglu, pone \emph{veradero}, y a partir de ahí se dirige al otro iglu y ve si es \emph{falso},
lo que significaría que está en la Sección Crítica.
\begin{itemize}
    \item
        \textbf{El problema}: surge cuando ambos procesos quieran poner \emph{verdadero} en sus respectivos iglues y
        salen a poner en la pizarra del otro proceso lo mismo; si ambos realizan lo mismo, entonces se convierte en un
        problema ya que nuevamente nos encontramos en una Exlusión Mutua
    \item
        \textbf{Interbloqueo}: Si la situación anterior se repite de manera continua, se produce un
        \textbf{interbloqueo}, porque cada uno vuelve a poner en su pizarra falso, luego los dos ponen verdadero, y así
        continuamente; la solución nº 3 tiene el problema del interbloqueo.
\end{itemize}

\subsubsection{Solución nº 4}

Esta solución es algo parecido con lo que hace el protocolo \emph{TCP/IP}.
Se implementa utilizando las características de la solución nº 3 pero con tiempo, es decir que en caso de que un proceso
vea dos verdadso en ambos iglues, lo que hace es esperar un tiempo aleatorio para poder volver a chequear las pizarra,
por lo que cada proceso en esta situación, podrá en algún momento entrar, ya que los tiempos que debe esperar son
\emph{aleatorios}. El problema que tiene acá es si los tiempos aleatorios se repiten, por lo que se vuelve al problema
nº 3, pero esto sucedería con una baja probabilidad.

\subsubsection{Solución nº 5}

Se implementa lo planteado por la solución nº 4 pero agregando un nuevo iglú que oficiará de árbitro, donde estaría
escrito el nº del proceso que está dentro de la Sección Crítica.

Pero es muy complicado de implementarlo para varios procesos.

\textbf{Pregunta de examen}: ¿Qué pasa si un proceso que está en la sección crítica muere? Esto es la problemática que
atraviesa a todos los intentos, si un proceso está ocupando la memoria criticia y muere, entonces se vuelve
problemático, ya que se estaría utilizando un recurso que nunca pasará a desbloquearse.

\subsection{Solución por Hardware}

Como las posibles soluciones anteriores eran difíciles de implementarlas vía software, se implementó una solución via
hardware.
Se pensó que haya en assembler una instrucción que permita bloquear el acceso a la Sección Critica.

\subsubsection{TSL}

TSL es una instrucción atómica en Assembler que permite crear un registro candado. Esto permite implementar una solución
de Software amparada en hardware

Como se dijo anteriormente,TSL (Test and Set Lock) es una operación que se utiliza frecuentemente cuando se tiene que
lidiar con problemas de índole general en Exclusión Mutua. Es una instrucción indivisible

\begin{itemize}
    \item
        ''candado'': es una variable compartida.
    \item
        El valor 0: permite paso (cualquiera lo puede poner a 1)
\end{itemize}

En informática, la instrucción test-and-set es una instrucción utilizada para escribir 1 (set) en una ubicación de
memoria y devolver su antiguo valor como una operación \textbf{atómica} única (es decir, no interrumpible). Si varios
procesos pueden acceder a la misma ubicación de memoria, y si un proceso está realizando una instrucción test-and-set,
ningún otro proceso puede comenzar otra instrucción de la misma índole hasta que finalice el test-and-set del primer
proceso.

Se declara una variable candado y se comparte entre todos los procesos que quieren entrar a la sección crítica.
La variable Candado es una variable como la que uno declara en C.

Cuando el Candado se encuentra en estado \emph{abierto} el valor por defecto es 0, por lo que significa que la sección
crítica está abierta para que se utilice la memoria. Un proceso pide el acceso a la Sección Crítica por lo que se fuerza
el 1 al registro Candado. Cuando otro proceso quiera acceder, se evalúa el registro Candado y al encontrarse en 1
(ocupado) se espera a que la sección sea desocupada.

Esta variable se comparte con el restro de los procesos que interactúan en la misma sección de memoria, no se sabe si
hay un proceso en la SC (Sección Critica), se guarda en un registro y se fuerza candado a 1, todo esto se hace de manera
ATOMICA; Esto NO es lo mismo que las soluciones por software.

Lo que permite esto es que haya si o si un solo proceso que pueda cambiar la variable Candado a la vez, y por ende que
entre a la Sección Crítica, garantizando de esta manera la Exlusión Mutua.  Cuando se va de la SC se pone el candado a
Cero (se hace con "MOV candado, 0")

Cabe destacar que la palabra atómica es INDISPENSABLE. Todo funciona porque el intercambio de valor de candados se hace
de manera indivisible, atómica, en un ciclo de reloj. No se pude dividir. Con esta instrucción se asegura que el
intercambio se produzca de manera indivisible, no interrumpible.

\subsubsection{XCHG}

XCHG (exchange data) es una instrucción en Assembler que permite el intercambio del contenido de dos operandos.
Lo que genera es el intercambio a nivel atómico del valor registro con el valor de la variable Candado.

\begin{itemize}
    \item
        \emph{reg = 1}: por lo tanto se intercambiará con el valor \emph{Candado = 0}.
    \item
        \emph{reg = 0}: por lo tanto se intercambiará con el valor \emph{Candado = 1}.
    \item
        \emph{reg = 1}: por lo tanto se intercambiará con el valor \emph{Candado = 0}. (Esto es lo mismo que hace TCL
        cuando registro tiene el valor 1)
\end{itemize}

\subsection{Semáforos (Mutex)}

Los Semáforos son soluciones que se implementan vía software.
Se proporcionan herramientas (liberías) que permiten generar semáforos (estas soluciones, por debajo ejecutan
instrucciones de tipo TSL).

\lstinputlisting[language={C}]{Clase4/ejemplo1.c}

Se debe recordar que la variable ''s'' implementada en el código anterior es de tipo entera y es compartida por los
procesos como variable Candado.

Función de la función \emph{wait()}:
\begin{itemize}
    \item
        \textbf{wait(s)}: si s es > 0 entonces s = s - 1. Decrementa el valor de s.
    \item
        \textbf{wait(s)}: si s es < 0 entonces espera a que la variable retorne a un valor mayor a 0.
    \item
        \textbf{signal(s)}: lo que genera es s = s + 1, incrementa el valor de S.
\end{itemize}

Modo de operar:

Un proceso si quiere entrar a la sección de memoria compartida, hace wait(s) sin saber si hay otro proceso en la
Sección Critica. La implementación dentro de la función \emph{wait(s)}, es lo mismo que se hace en \emph{TSL}. Cuando
está en s = 1, está en verde, lo que hace es hacerle un s--. Cuando se termina de hacer lo que se tiene que hacer, se
hace un signal(s) que lo que haría sería un s++.

\subsection{Problema de la cena de los filósofos}

Consiste en 5 filósofos y en el medio de la mesa hay un plato. Cada filósofo tiene un tenedor. Cada filósofo es un
proceso y el tenedor es un recurso. Lo que hace un filósofo es o comer o filosofar. Solo pueden comer con 2
cubiertos. El problema se plantea cuando dos filósofos contiguos quieren comer (ya que tiene los cubiertos, recursos
ocupados).

\textbf{Pregunta de examen}: ¿Cómo podría darse un interbloqueo en la cena de los filósofos?
Se debe dibujar el esquema de la mesa reonda y explicar cómo se toman los recursos . Lo que se hace es programar todos
los filósofos iguales, que pidan el recurso de la derecha y esperen el de la izquierda. Si hacen todos esto al mismo
tiempo, se produce un deadlock.

\subsection{Problema de la barrera}

Otro problema que se plantea con procesos concurrentes.

En un punto de sincronización donde los 3 procesos tienen que llegar para poder seguir ejecutando del otro lado de la barrera.
La barrera es un punto de sincronización donde todos los procesos a distintos tiempos deben llegar para poder seguir
ejecutando del otro lado de la barrera.

La barrera se pude ver como un array lleno de 0 que cuando llga cada uno de los procesos se guarda el 1.

\subsection{MicroKernel}

Se parte del siguiente análisis: \emph{Cada 1000 líneas de código se encuentran 10 errores}. Los caules tienen que ver
en su gran mayoría con la seguridad del sistema.

Siguiendo lo anterior, En un sistema operativo con 5 millones de lineas se tienen 50 mil errores. Por lo que hay muchos
problemas sobre todo de seguridad que hay que resolver.

Como hay tantos errores entonces se pensó lo siguiente: depurar el kernel, por lo que se toman las rutinas más
importantes y son colocadas como bases del kernel para que sea lo más simple posible.

\subsubsection{Kernel Monolítico}

En un Kernel cuya organización es monolítica; debajo de todo se encuentra el hardware, por encima de ello los Servicios
de Scheduling (proceso que se encarga de elegir qué proceso y por cuánto tiempo le corresponde correr en el micro
procesador). La misma es una rutina de software del sistema operativo.

Por sobre el anterior, está el Memory Manager: administrador de la memoria que le indica qué cantidad de memoria le
correspnde cada programa.

Por sobre ellos se encuentran los Servicios de I/O Manager el cual administra las entradas y salidas del sistema; y el
FS (que es el que se encarga de que todos los archivos parezcan como que están organizadas)

Sistem Servicess: Ataja las solicitudes de las aplicaciones al sistema operativo. Por sobre ello se encuentra el modo
usuario de los procesos de usuario.

\emph{Modo Kernel}: Lo que no se puede tocar, lo que está ya compilado.

Los sistemas de tipo GNU/Linux se encuentran estructurados como un Kernel Monolítico.

\subsubsection{MicroKernel}

Por debajo se encuentra el hardware. Sobre ello una rutina que se denomina ''microkernel'' y por sobre ella el \emph{modo
usuario}. En el \emph{espacio de usuario} es donde se encuentran las rutinas que antes pertenecían al modo kernel. Es
por ello que gran parte del SO puede ser manipulado por el usuario.

La idea es tener la rutina de MicroKernel lo más chica y simple posible para que no hayan bugs de seguridad en
contraposición al otro tipo de kernel (monolítico).

\textbf{Ventajas}:
\begin{itemize}
    \item
        Manejador de IO por ejemplo, si se quiere cambiar un driver, se puede desinstalar e instalar otro como si fuera
        una aplicación de usuario.  Se tiende a la seguridad por ser el MircroKernel ser lo más simple posible. Con esto
        se gana en modularidad y en seguridad.
    \item
        Podemos cambiar un servicio del SO, cambiando el proceso que lo implementa. Podemos ejecutar programas
        realizados para otros distinto.
    \item
        Un posible error de un servicio del SO queda confinado en el espacio de direcciones del proceso que lo
        implementa. Es extensible y personalizable.
\end{itemize}

\vspace{15pt}
\textbf{Desventajas}:
\begin{itemize}
    \item
        Por otro lado, sus principales dificultades son la complejidad en la sincronización de todos los módulos que
        componen el micronúcleo y su acceso a la memoria, la anulación de las ventajas de Zero Copy, la Integración con
        las aplicaciones. Además, los procesadores y arquitecturas modernas de hardware están optimizadas para sistemas
        de núcleo que pueden mapear toda la memoria.
    \item
        Esto mejora la tolerancia a fallos y eleva la portabilidad entre plataformas de hardware, según los defensores
        de esta tendencia. Sus detractores le achacan, fundamentalmente, mayor complejidad en el código, menor
        rendimiento, o limitaciones en diversas funciones.
\end{itemize}

\textbf{Pregunta de examen}: ¿Cual es la motiviación para implementar SO de Micro kernel? ¿cuáles son las ventajas de
ello?

\end{document}
